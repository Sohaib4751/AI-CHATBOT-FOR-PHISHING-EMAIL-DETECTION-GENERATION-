from transformers import BertTokenizer, BertForSequenceClassification
import torch

# âœ… Load model and tokenizer
model_path = "detector/bert_detector_model"
model = BertForSequenceClassification.from_pretrained(model_path)
tokenizer = BertTokenizer.from_pretrained(model_path)
model.eval()

# ğŸ£ Take user input
email_text = input("ğŸ“¨ Email: ")

# âœï¸ Tokenize
inputs = tokenizer(email_text, return_tensors="pt", truncation=True, padding=True)

# ğŸ” Predict
with torch.no_grad():
    outputs = model(**inputs)
    probs = torch.nn.functional.softmax(outputs.logits, dim=1)
    phishing_confidence = probs[0][1].item()
    legitimate_confidence = probs[0][0].item()

# ğŸ§  Prediction based on threshold
threshold = 0.6
if phishing_confidence > threshold:
    label = "Phishing"
else:
    label = "Legitimate"

# ğŸ“Š Output
print(f"\nğŸ§  Prediction: {label}")
print(f"ğŸ” Phishing Confidence: {phishing_confidence:.2f}")
print(f"ğŸ“¬ Legitimate Confidence: {legitimate_confidence:.2f}")
